{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3424657534246575,
  "eval_steps": 500,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01141552511415525,
      "grad_norm": 1.3151443004608154,
      "learning_rate": 1.9771689497716898e-05,
      "loss": 2.6653,
      "step": 500
    },
    {
      "epoch": 0.0228310502283105,
      "grad_norm": 1.3846060037612915,
      "learning_rate": 1.954337899543379e-05,
      "loss": 2.6034,
      "step": 1000
    },
    {
      "epoch": 0.03424657534246575,
      "grad_norm": 1.444757342338562,
      "learning_rate": 1.9315525114155254e-05,
      "loss": 2.57,
      "step": 1500
    },
    {
      "epoch": 0.045662100456621,
      "grad_norm": 1.553785800933838,
      "learning_rate": 1.9087214611872146e-05,
      "loss": 2.5679,
      "step": 2000
    },
    {
      "epoch": 0.05707762557077625,
      "grad_norm": 1.190148949623108,
      "learning_rate": 1.8858904109589042e-05,
      "loss": 2.5368,
      "step": 2500
    },
    {
      "epoch": 0.0684931506849315,
      "grad_norm": 1.4452345371246338,
      "learning_rate": 1.863059360730594e-05,
      "loss": 2.559,
      "step": 3000
    },
    {
      "epoch": 0.07990867579908675,
      "grad_norm": 1.2388166189193726,
      "learning_rate": 1.8402283105022834e-05,
      "loss": 2.5432,
      "step": 3500
    },
    {
      "epoch": 0.091324200913242,
      "grad_norm": 1.1264398097991943,
      "learning_rate": 1.8174429223744294e-05,
      "loss": 2.5388,
      "step": 4000
    },
    {
      "epoch": 0.10273972602739725,
      "grad_norm": 1.2158843278884888,
      "learning_rate": 1.7946118721461187e-05,
      "loss": 2.5247,
      "step": 4500
    },
    {
      "epoch": 0.1141552511415525,
      "grad_norm": 0.7957170605659485,
      "learning_rate": 1.771826484018265e-05,
      "loss": 2.5369,
      "step": 5000
    },
    {
      "epoch": 0.12557077625570776,
      "grad_norm": 1.0614144802093506,
      "learning_rate": 1.7489954337899543e-05,
      "loss": 2.5586,
      "step": 5500
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 1.3078621625900269,
      "learning_rate": 1.726164383561644e-05,
      "loss": 2.5358,
      "step": 6000
    },
    {
      "epoch": 0.14840182648401826,
      "grad_norm": 1.6278350353240967,
      "learning_rate": 1.70337899543379e-05,
      "loss": 2.5407,
      "step": 6500
    },
    {
      "epoch": 0.1598173515981735,
      "grad_norm": 1.9384424686431885,
      "learning_rate": 1.6805479452054795e-05,
      "loss": 2.5136,
      "step": 7000
    },
    {
      "epoch": 0.17123287671232876,
      "grad_norm": 1.000634789466858,
      "learning_rate": 1.657716894977169e-05,
      "loss": 2.517,
      "step": 7500
    },
    {
      "epoch": 0.182648401826484,
      "grad_norm": 1.1523184776306152,
      "learning_rate": 1.6348858447488584e-05,
      "loss": 2.545,
      "step": 8000
    },
    {
      "epoch": 0.19406392694063926,
      "grad_norm": 1.3953224420547485,
      "learning_rate": 1.612054794520548e-05,
      "loss": 2.5087,
      "step": 8500
    },
    {
      "epoch": 0.2054794520547945,
      "grad_norm": 1.018192172050476,
      "learning_rate": 1.5892237442922376e-05,
      "loss": 2.5362,
      "step": 9000
    },
    {
      "epoch": 0.21689497716894976,
      "grad_norm": 1.171452283859253,
      "learning_rate": 1.5663926940639272e-05,
      "loss": 2.5484,
      "step": 9500
    },
    {
      "epoch": 0.228310502283105,
      "grad_norm": 1.3134640455245972,
      "learning_rate": 1.5435616438356164e-05,
      "loss": 2.5429,
      "step": 10000
    },
    {
      "epoch": 0.23972602739726026,
      "grad_norm": 1.2987244129180908,
      "learning_rate": 1.520730593607306e-05,
      "loss": 2.517,
      "step": 10500
    },
    {
      "epoch": 0.2511415525114155,
      "grad_norm": 2.091269016265869,
      "learning_rate": 1.4978995433789956e-05,
      "loss": 2.5215,
      "step": 11000
    },
    {
      "epoch": 0.2625570776255708,
      "grad_norm": 1.6012133359909058,
      "learning_rate": 1.475068493150685e-05,
      "loss": 2.5108,
      "step": 11500
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 1.3596328496932983,
      "learning_rate": 1.4522374429223745e-05,
      "loss": 2.5247,
      "step": 12000
    },
    {
      "epoch": 0.2853881278538813,
      "grad_norm": 1.4388612508773804,
      "learning_rate": 1.429406392694064e-05,
      "loss": 2.5031,
      "step": 12500
    },
    {
      "epoch": 0.2968036529680365,
      "grad_norm": 1.299344539642334,
      "learning_rate": 1.4065753424657535e-05,
      "loss": 2.5358,
      "step": 13000
    },
    {
      "epoch": 0.3082191780821918,
      "grad_norm": 1.4562537670135498,
      "learning_rate": 1.3837899543378997e-05,
      "loss": 2.5182,
      "step": 13500
    },
    {
      "epoch": 0.319634703196347,
      "grad_norm": 1.3148980140686035,
      "learning_rate": 1.3609589041095891e-05,
      "loss": 2.5324,
      "step": 14000
    },
    {
      "epoch": 0.3310502283105023,
      "grad_norm": 1.9310884475708008,
      "learning_rate": 1.3381278538812787e-05,
      "loss": 2.5245,
      "step": 14500
    },
    {
      "epoch": 0.3424657534246575,
      "grad_norm": 1.4969720840454102,
      "learning_rate": 1.315296803652968e-05,
      "loss": 2.5322,
      "step": 15000
    }
  ],
  "logging_steps": 500,
  "max_steps": 43800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3212500254195712e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
