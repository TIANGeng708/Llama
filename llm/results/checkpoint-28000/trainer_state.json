{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.639269406392694,
  "eval_steps": 500,
  "global_step": 28000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01141552511415525,
      "grad_norm": 1.3151443004608154,
      "learning_rate": 1.9771689497716898e-05,
      "loss": 2.6653,
      "step": 500
    },
    {
      "epoch": 0.0228310502283105,
      "grad_norm": 1.3846060037612915,
      "learning_rate": 1.954337899543379e-05,
      "loss": 2.6034,
      "step": 1000
    },
    {
      "epoch": 0.03424657534246575,
      "grad_norm": 1.444757342338562,
      "learning_rate": 1.9315525114155254e-05,
      "loss": 2.57,
      "step": 1500
    },
    {
      "epoch": 0.045662100456621,
      "grad_norm": 1.553785800933838,
      "learning_rate": 1.9087214611872146e-05,
      "loss": 2.5679,
      "step": 2000
    },
    {
      "epoch": 0.05707762557077625,
      "grad_norm": 1.190148949623108,
      "learning_rate": 1.8858904109589042e-05,
      "loss": 2.5368,
      "step": 2500
    },
    {
      "epoch": 0.0684931506849315,
      "grad_norm": 1.4452345371246338,
      "learning_rate": 1.863059360730594e-05,
      "loss": 2.559,
      "step": 3000
    },
    {
      "epoch": 0.07990867579908675,
      "grad_norm": 1.2388166189193726,
      "learning_rate": 1.8402283105022834e-05,
      "loss": 2.5432,
      "step": 3500
    },
    {
      "epoch": 0.091324200913242,
      "grad_norm": 1.1264398097991943,
      "learning_rate": 1.8174429223744294e-05,
      "loss": 2.5388,
      "step": 4000
    },
    {
      "epoch": 0.10273972602739725,
      "grad_norm": 1.2158843278884888,
      "learning_rate": 1.7946118721461187e-05,
      "loss": 2.5247,
      "step": 4500
    },
    {
      "epoch": 0.1141552511415525,
      "grad_norm": 0.7957170605659485,
      "learning_rate": 1.771826484018265e-05,
      "loss": 2.5369,
      "step": 5000
    },
    {
      "epoch": 0.12557077625570776,
      "grad_norm": 1.0614144802093506,
      "learning_rate": 1.7489954337899543e-05,
      "loss": 2.5586,
      "step": 5500
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 1.3078621625900269,
      "learning_rate": 1.726164383561644e-05,
      "loss": 2.5358,
      "step": 6000
    },
    {
      "epoch": 0.14840182648401826,
      "grad_norm": 1.6278350353240967,
      "learning_rate": 1.70337899543379e-05,
      "loss": 2.5407,
      "step": 6500
    },
    {
      "epoch": 0.1598173515981735,
      "grad_norm": 1.9384424686431885,
      "learning_rate": 1.6805479452054795e-05,
      "loss": 2.5136,
      "step": 7000
    },
    {
      "epoch": 0.17123287671232876,
      "grad_norm": 1.000634789466858,
      "learning_rate": 1.657716894977169e-05,
      "loss": 2.517,
      "step": 7500
    },
    {
      "epoch": 0.182648401826484,
      "grad_norm": 1.1523184776306152,
      "learning_rate": 1.6348858447488584e-05,
      "loss": 2.545,
      "step": 8000
    },
    {
      "epoch": 0.19406392694063926,
      "grad_norm": 1.3953224420547485,
      "learning_rate": 1.612054794520548e-05,
      "loss": 2.5087,
      "step": 8500
    },
    {
      "epoch": 0.2054794520547945,
      "grad_norm": 1.018192172050476,
      "learning_rate": 1.5892237442922376e-05,
      "loss": 2.5362,
      "step": 9000
    },
    {
      "epoch": 0.21689497716894976,
      "grad_norm": 1.171452283859253,
      "learning_rate": 1.5663926940639272e-05,
      "loss": 2.5484,
      "step": 9500
    },
    {
      "epoch": 0.228310502283105,
      "grad_norm": 1.3134640455245972,
      "learning_rate": 1.5435616438356164e-05,
      "loss": 2.5429,
      "step": 10000
    },
    {
      "epoch": 0.23972602739726026,
      "grad_norm": 1.2987244129180908,
      "learning_rate": 1.520730593607306e-05,
      "loss": 2.517,
      "step": 10500
    },
    {
      "epoch": 0.2511415525114155,
      "grad_norm": 2.091269016265869,
      "learning_rate": 1.4978995433789956e-05,
      "loss": 2.5215,
      "step": 11000
    },
    {
      "epoch": 0.2625570776255708,
      "grad_norm": 1.6012133359909058,
      "learning_rate": 1.475068493150685e-05,
      "loss": 2.5108,
      "step": 11500
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 1.3596328496932983,
      "learning_rate": 1.4522374429223745e-05,
      "loss": 2.5247,
      "step": 12000
    },
    {
      "epoch": 0.2853881278538813,
      "grad_norm": 1.4388612508773804,
      "learning_rate": 1.429406392694064e-05,
      "loss": 2.5031,
      "step": 12500
    },
    {
      "epoch": 0.2968036529680365,
      "grad_norm": 1.299344539642334,
      "learning_rate": 1.4065753424657535e-05,
      "loss": 2.5358,
      "step": 13000
    },
    {
      "epoch": 0.3082191780821918,
      "grad_norm": 1.4562537670135498,
      "learning_rate": 1.3837899543378997e-05,
      "loss": 2.5182,
      "step": 13500
    },
    {
      "epoch": 0.319634703196347,
      "grad_norm": 1.3148980140686035,
      "learning_rate": 1.3609589041095891e-05,
      "loss": 2.5324,
      "step": 14000
    },
    {
      "epoch": 0.3310502283105023,
      "grad_norm": 1.9310884475708008,
      "learning_rate": 1.3381278538812787e-05,
      "loss": 2.5245,
      "step": 14500
    },
    {
      "epoch": 0.3424657534246575,
      "grad_norm": 1.4969720840454102,
      "learning_rate": 1.315296803652968e-05,
      "loss": 2.5322,
      "step": 15000
    },
    {
      "epoch": 0.3538812785388128,
      "grad_norm": 1.2639079093933105,
      "learning_rate": 1.2924657534246576e-05,
      "loss": 2.5256,
      "step": 15500
    },
    {
      "epoch": 0.365296803652968,
      "grad_norm": 1.1381916999816895,
      "learning_rate": 1.2696347031963472e-05,
      "loss": 2.5245,
      "step": 16000
    },
    {
      "epoch": 0.3767123287671233,
      "grad_norm": 1.634807825088501,
      "learning_rate": 1.2468036529680368e-05,
      "loss": 2.5189,
      "step": 16500
    },
    {
      "epoch": 0.3881278538812785,
      "grad_norm": 1.165611743927002,
      "learning_rate": 1.223972602739726e-05,
      "loss": 2.5143,
      "step": 17000
    },
    {
      "epoch": 0.3995433789954338,
      "grad_norm": 1.9227540493011475,
      "learning_rate": 1.2011415525114157e-05,
      "loss": 2.5236,
      "step": 17500
    },
    {
      "epoch": 0.410958904109589,
      "grad_norm": 1.1458616256713867,
      "learning_rate": 1.1783561643835617e-05,
      "loss": 2.5265,
      "step": 18000
    },
    {
      "epoch": 0.4223744292237443,
      "grad_norm": 1.081174373626709,
      "learning_rate": 1.1555251141552513e-05,
      "loss": 2.5164,
      "step": 18500
    },
    {
      "epoch": 0.4337899543378995,
      "grad_norm": 1.6821699142456055,
      "learning_rate": 1.1326940639269409e-05,
      "loss": 2.5279,
      "step": 19000
    },
    {
      "epoch": 0.4452054794520548,
      "grad_norm": 1.2844908237457275,
      "learning_rate": 1.1098630136986301e-05,
      "loss": 2.5055,
      "step": 19500
    },
    {
      "epoch": 0.45662100456621,
      "grad_norm": 1.471086025238037,
      "learning_rate": 1.0870776255707765e-05,
      "loss": 2.5199,
      "step": 20000
    },
    {
      "epoch": 0.4680365296803653,
      "grad_norm": 1.6320240497589111,
      "learning_rate": 1.0642922374429225e-05,
      "loss": 2.5152,
      "step": 20500
    },
    {
      "epoch": 0.4794520547945205,
      "grad_norm": 1.7649928331375122,
      "learning_rate": 1.041461187214612e-05,
      "loss": 2.4968,
      "step": 21000
    },
    {
      "epoch": 0.4908675799086758,
      "grad_norm": 0.948176383972168,
      "learning_rate": 1.0186301369863013e-05,
      "loss": 2.5229,
      "step": 21500
    },
    {
      "epoch": 0.502283105022831,
      "grad_norm": 1.4560186862945557,
      "learning_rate": 9.95799086757991e-06,
      "loss": 2.5176,
      "step": 22000
    },
    {
      "epoch": 0.5136986301369864,
      "grad_norm": 1.3319660425186157,
      "learning_rate": 9.729680365296804e-06,
      "loss": 2.5301,
      "step": 22500
    },
    {
      "epoch": 0.5251141552511416,
      "grad_norm": 1.3525234460830688,
      "learning_rate": 9.5013698630137e-06,
      "loss": 2.5336,
      "step": 23000
    },
    {
      "epoch": 0.5365296803652968,
      "grad_norm": 1.55711030960083,
      "learning_rate": 9.27351598173516e-06,
      "loss": 2.5134,
      "step": 23500
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 1.0013631582260132,
      "learning_rate": 9.045205479452056e-06,
      "loss": 2.5271,
      "step": 24000
    },
    {
      "epoch": 0.5593607305936074,
      "grad_norm": 1.476867437362671,
      "learning_rate": 8.81689497716895e-06,
      "loss": 2.5064,
      "step": 24500
    },
    {
      "epoch": 0.5707762557077626,
      "grad_norm": 1.6593352556228638,
      "learning_rate": 8.589041095890412e-06,
      "loss": 2.4874,
      "step": 25000
    },
    {
      "epoch": 0.5821917808219178,
      "grad_norm": 1.2006417512893677,
      "learning_rate": 8.360730593607306e-06,
      "loss": 2.5148,
      "step": 25500
    },
    {
      "epoch": 0.593607305936073,
      "grad_norm": 1.7505563497543335,
      "learning_rate": 8.1324200913242e-06,
      "loss": 2.4952,
      "step": 26000
    },
    {
      "epoch": 0.6050228310502284,
      "grad_norm": 1.0151028633117676,
      "learning_rate": 7.904109589041097e-06,
      "loss": 2.5273,
      "step": 26500
    },
    {
      "epoch": 0.6164383561643836,
      "grad_norm": 1.233444094657898,
      "learning_rate": 7.675799086757991e-06,
      "loss": 2.5178,
      "step": 27000
    },
    {
      "epoch": 0.6278538812785388,
      "grad_norm": 1.3314096927642822,
      "learning_rate": 7.447488584474887e-06,
      "loss": 2.5,
      "step": 27500
    },
    {
      "epoch": 0.639269406392694,
      "grad_norm": 1.3448126316070557,
      "learning_rate": 7.219178082191781e-06,
      "loss": 2.5046,
      "step": 28000
    }
  ],
  "logging_steps": 500,
  "max_steps": 43800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.333000047449866e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
